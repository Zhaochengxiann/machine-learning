{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046188,
     "end_time": "2021-12-27T09:58:28.943899",
     "exception": false,
     "start_time": "2021-12-27T09:58:28.897711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate music with variational autoEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044631,
     "end_time": "2021-12-27T09:58:29.034304",
     "exception": false,
     "start_time": "2021-12-27T09:58:28.989673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "This work is inspired by the research paper [Jukebox: A Generative Model for Music](https://cdn.openai.com/papers/jukebox.pdf). In this notebook, we have developed a generative model that could generate music from a variational autoencoder trained with a category of music. We have selected the jazz and classical music categories. The entire model is implemented in TensorFlow and used Librosa for audio processing. The input sampling rate is 3000 for processing the audio file into a readable array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:06.710523Z",
     "iopub.status.busy": "2021-12-27T09:59:06.709364Z",
     "iopub.status.idle": "2021-12-27T09:59:13.067225Z",
     "shell.execute_reply": "2021-12-27T09:59:13.067844Z",
     "shell.execute_reply.started": "2021-11-21T00:58:24.067518Z"
    },
    "id": "9dW17ecr5IYC",
    "papermill": {
     "duration": 6.410043,
     "end_time": "2021-12-27T09:59:13.068020",
     "exception": false,
     "start_time": "2021-12-27T09:59:06.657977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import time\n",
    "import IPython.display as ipd\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:13.166576Z",
     "iopub.status.busy": "2021-12-27T09:59:13.165847Z",
     "iopub.status.idle": "2021-12-27T09:59:15.056428Z",
     "shell.execute_reply": "2021-12-27T09:59:15.055781Z",
     "shell.execute_reply.started": "2021-11-21T00:58:29.325166Z"
    },
    "id": "Rf_iJJoWEkEF",
    "papermill": {
     "duration": 1.942125,
     "end_time": "2021-12-27T09:59:15.056555",
     "exception": false,
     "start_time": "2021-12-27T09:59:13.114430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1, inter_op_parallelism_threads=1\n",
    ")\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:15.153545Z",
     "iopub.status.busy": "2021-12-27T09:59:15.152439Z",
     "iopub.status.idle": "2021-12-27T09:59:15.155065Z",
     "shell.execute_reply": "2021-12-27T09:59:15.155606Z",
     "shell.execute_reply.started": "2021-11-21T01:12:36.325934Z"
    },
    "id": "BLdVyNVHrFF1",
    "papermill": {
     "duration": 0.054297,
     "end_time": "2021-12-27T09:59:15.155738",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.101441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "BATCH_SIZE = 10\n",
    "test_size = 10000\n",
    "epochs = 20\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 10\n",
    "\n",
    "BASE_PATH = \"../../assets/data/jazz\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044842,
     "end_time": "2021-12-27T09:59:15.244866",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.200024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:15.345594Z",
     "iopub.status.busy": "2021-12-27T09:59:15.344681Z",
     "iopub.status.idle": "2021-12-27T09:59:15.348922Z",
     "shell.execute_reply": "2021-12-27T09:59:15.348423Z",
     "shell.execute_reply.started": "2021-11-21T00:58:30.950386Z"
    },
    "id": "NtThS3oVWU85",
    "papermill": {
     "duration": 0.059222,
     "end_time": "2021-12-27T09:59:15.349083",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.289861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DatasetLoader():\n",
    "    music_list = np.array(sorted(os.listdir(BASE_PATH)))\n",
    "    train_music_1 = list(\n",
    "        music_list[[0, 5, 19, 3, 7, 12, 10, 8, 30, 25, 24, 14, 27]]\n",
    "    )  # 99,10,66,76,41\n",
    "    # 65,32,53,22,19,80,89,\n",
    "    train_music_2 = list(music_list[[4, 23, 29, 34, 33, 31, 11, 13, 14, 30, 21, 22]])\n",
    "    TrackSet_1 = [(BASE_PATH) + \"/%s\" % (x) for x in train_music_1]\n",
    "    TrackSet_2 = [(BASE_PATH) + \"/%s\" % (x) for x in train_music_2]\n",
    "\n",
    "    return TrackSet_1, TrackSet_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:15.448120Z",
     "iopub.status.busy": "2021-12-27T09:59:15.446997Z",
     "iopub.status.idle": "2021-12-27T09:59:15.450298Z",
     "shell.execute_reply": "2021-12-27T09:59:15.450827Z",
     "shell.execute_reply.started": "2021-11-21T00:58:30.965109Z"
    },
    "id": "72nbIzueCYWq",
    "papermill": {
     "duration": 0.0563,
     "end_time": "2021-12-27T09:59:15.450966",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.394666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(file_):\n",
    "    data_, sampling_rate = librosa.load(file_, sr=3000, offset=0.0, duration=30)\n",
    "    data_ = data_.reshape(1, 90001)\n",
    "    return data_\n",
    "\n",
    "\n",
    "def map_data(filename):\n",
    "    return tf.compat.v1.py_func(load, [filename], [tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:15.546073Z",
     "iopub.status.busy": "2021-12-27T09:59:15.545434Z",
     "iopub.status.idle": "2021-12-27T09:59:15.582845Z",
     "shell.execute_reply": "2021-12-27T09:59:15.582276Z",
     "shell.execute_reply.started": "2021-11-21T00:58:30.975943Z"
    },
    "id": "Z-q0fDhfeek_",
    "papermill": {
     "duration": 0.086083,
     "end_time": "2021-12-27T09:59:15.582959",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.496876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TrackSet_1, TrackSet_2 = DatasetLoader()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045401,
     "end_time": "2021-12-27T09:59:15.672122",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.626721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## sample original music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:15.767430Z",
     "iopub.status.busy": "2021-12-27T09:59:15.766692Z",
     "iopub.status.idle": "2021-12-27T09:59:17.288512Z",
     "shell.execute_reply": "2021-12-27T09:59:17.289602Z",
     "shell.execute_reply.started": "2021-11-21T00:58:31.030615Z"
    },
    "papermill": {
     "duration": 1.572165,
     "end_time": "2021-12-27T09:59:17.289772",
     "exception": false,
     "start_time": "2021-12-27T09:59:15.717607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = TrackSet_1[1]\n",
    "sample_, sampling_rate = librosa.load(sample, sr=3000, offset=0.0, duration=30)\n",
    "ipd.Audio(sample_, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:17.396222Z",
     "iopub.status.busy": "2021-12-27T09:59:17.395128Z",
     "iopub.status.idle": "2021-12-27T09:59:21.595645Z",
     "shell.execute_reply": "2021-12-27T09:59:21.596199Z",
     "shell.execute_reply.started": "2021-11-21T00:58:32.231423Z"
    },
    "id": "tTb_ETmUB80m",
    "outputId": "f4bdb49c-8183-4b8a-cc3a-bcbe89fa5369",
    "papermill": {
     "duration": 4.256473,
     "end_time": "2021-12-27T09:59:21.596359",
     "exception": false,
     "start_time": "2021-12-27T09:59:17.339886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(18, 15))\n",
    "for i in range(4):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    j = load(TrackSet_1[i])\n",
    "    librosa.display.waveshow(j[0], sr=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:21.713365Z",
     "iopub.status.busy": "2021-12-27T09:59:21.709667Z",
     "iopub.status.idle": "2021-12-27T09:59:22.184999Z",
     "shell.execute_reply": "2021-12-27T09:59:22.184258Z",
     "shell.execute_reply.started": "2021-11-21T01:12:40.137035Z"
    },
    "id": "WFrXrtoFPX1r",
    "outputId": "9395bfcc-2015-4e42-c8b8-f83a497295f7",
    "papermill": {
     "duration": 0.539245,
     "end_time": "2021-12-27T09:59:22.185160",
     "exception": false,
     "start_time": "2021-12-27T09:59:21.645915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((TrackSet_1))\n",
    "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(3)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((TrackSet_2))\n",
    "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(3)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050344,
     "end_time": "2021-12-27T09:59:22.285941",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.235597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explaining the concept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051999,
     "end_time": "2021-12-27T09:59:22.387111",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.335112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder network\n",
    "This defines the approximate posterior distribution *q(z|x)*, which takes as input an observation and outputs a set of parameters for specifying the conditional distribution of the latent representation *z*. In this example, we simply model the distribution as a diagonal Gaussian, and the network outputs the mean and log-variance parameters of a factorized Gaussian. We output log-variance instead of the variance directly for numerical stability.\n",
    "## Decoder network\n",
    "This defines the conditional distribution of the observation *p(x|z)*, which takes a latent sample *z* as input and outputs the parameters for a conditional distribution of the observation. We model the latent distribution prior *p(z)* as a unit Gaussian.\n",
    "## Reparameterization\n",
    "To generate a sample *z* for the decoder during training, we can sample from the latent distribution defined by the parameters outputted by the encoder, given an input observation *x*. However, this sampling operation creates a bottleneck because backpropagation cannot flow through a random node.\n",
    "\n",
    "To address this, we use a reparameterization trick. In our example, we approximate *z* using the decoder parameters and another parameter *ϵ* as follows:\n",
    "\n",
    "z = μ + σ.ϵ\n",
    "\n",
    "Source: [Tensorflow](https://www.tensorflow.org/tutorials/generative/cvae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050801,
     "end_time": "2021-12-27T09:59:22.488688",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.437887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:22.606635Z",
     "iopub.status.busy": "2021-12-27T09:59:22.605429Z",
     "iopub.status.idle": "2021-12-27T09:59:22.607691Z",
     "shell.execute_reply": "2021-12-27T09:59:22.608418Z",
     "shell.execute_reply.started": "2021-11-21T01:12:43.251305Z"
    },
    "id": "qo4mCvIvvl25",
    "papermill": {
     "duration": 0.069232,
     "end_time": "2021-12-27T09:59:22.608554",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.539322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resnet1DBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters, type=\"encode\"):\n",
    "        super(Resnet1DBlock, self).__init__()\n",
    "\n",
    "        if type == \"encode\":\n",
    "            self.conv1a = layers.Conv1D(filters, kernel_size, 2, padding=\"same\")\n",
    "            self.conv1b = layers.Conv1D(filters, kernel_size, 1, padding=\"same\")\n",
    "            self.norm1a = tfa.layers.InstanceNormalization()\n",
    "            self.norm1b = tfa.layers.InstanceNormalization()\n",
    "        if type == \"decode\":\n",
    "            self.conv1a = layers.Conv1DTranspose(\n",
    "                filters, kernel_size, 1, padding=\"same\"\n",
    "            )\n",
    "            self.conv1b = layers.Conv1DTranspose(\n",
    "                filters, kernel_size, 1, padding=\"same\"\n",
    "            )\n",
    "            self.norm1a = tf.keras.layers.BatchNormalization()\n",
    "            self.norm1b = tf.keras.layers.BatchNormalization()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.relu(input_tensor)\n",
    "        x = self.conv1a(x)\n",
    "        x = self.norm1a(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "\n",
    "        x = self.conv1b(x)\n",
    "        x = self.norm1b(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:22.731894Z",
     "iopub.status.busy": "2021-12-27T09:59:22.729518Z",
     "iopub.status.idle": "2021-12-27T09:59:22.732671Z",
     "shell.execute_reply": "2021-12-27T09:59:22.733237Z",
     "shell.execute_reply.started": "2021-11-21T01:12:43.811107Z"
    },
    "id": "unLIGpdE-6t-",
    "papermill": {
     "duration": 0.075126,
     "end_time": "2021-12-27T09:59:22.733390",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.658264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(1, 90001)),\n",
    "                layers.Conv1D(64, 1, 2),\n",
    "                Resnet1DBlock(64, 1),\n",
    "                layers.Conv1D(128, 1, 2),\n",
    "                Resnet1DBlock(128, 1),\n",
    "                layers.Conv1D(128, 1, 2),\n",
    "                Resnet1DBlock(128, 1),\n",
    "                layers.Conv1D(256, 1, 2),\n",
    "                Resnet1DBlock(256, 1),\n",
    "                # No activation\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                layers.Reshape(target_shape=(1, latent_dim)),\n",
    "                Resnet1DBlock(512, 1, \"decode\"),\n",
    "                layers.Conv1DTranspose(512, 1, 1),\n",
    "                Resnet1DBlock(256, 1, \"decode\"),\n",
    "                layers.Conv1DTranspose(256, 1, 1),\n",
    "                Resnet1DBlock(128, 1, \"decode\"),\n",
    "                layers.Conv1DTranspose(128, 1, 1),\n",
    "                Resnet1DBlock(64, 1, \"decode\"),\n",
    "                layers.Conv1DTranspose(64, 1, 1),\n",
    "                # No activation\n",
    "                layers.Conv1DTranspose(90001, 1, 1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(200, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    @tf.function\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    @tf.function\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    @tf.function\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:22.838609Z",
     "iopub.status.busy": "2021-12-27T09:59:22.837590Z",
     "iopub.status.idle": "2021-12-27T09:59:22.841416Z",
     "shell.execute_reply": "2021-12-27T09:59:22.840755Z",
     "shell.execute_reply.started": "2021-11-21T01:12:44.481534Z"
    },
    "id": "HjF7biGGEKML",
    "papermill": {
     "duration": 0.058902,
     "end_time": "2021-12-27T09:59:22.841532",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.782630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:22.950111Z",
     "iopub.status.busy": "2021-12-27T09:59:22.948954Z",
     "iopub.status.idle": "2021-12-27T09:59:22.952858Z",
     "shell.execute_reply": "2021-12-27T09:59:22.952261Z",
     "shell.execute_reply.started": "2021-11-21T01:12:47.064811Z"
    },
    "id": "o-RrkE6mG9Zp",
    "papermill": {
     "duration": 0.061403,
     "end_time": "2021-12-27T09:59:22.952985",
     "exception": false,
     "start_time": "2021-12-27T09:59:22.891582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2.0 * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -0.5 * ((sample - mean) ** 2.0 * tf.exp(-logvar) + logvar + log2pi), axis=raxis\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:23.065616Z",
     "iopub.status.busy": "2021-12-27T09:59:23.064507Z",
     "iopub.status.idle": "2021-12-27T09:59:23.068409Z",
     "shell.execute_reply": "2021-12-27T09:59:23.067851Z",
     "shell.execute_reply.started": "2021-11-21T01:12:48.056745Z"
    },
    "id": "KHmERgizHMAQ",
    "papermill": {
     "duration": 0.063792,
     "end_time": "2021-12-27T09:59:23.068541",
     "exception": false,
     "start_time": "2021-12-27T09:59:23.004749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])\n",
    "    logpz = log_normal_pdf(z, 0.0, 0.0)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049479,
     "end_time": "2021-12-27T09:59:23.168852",
     "exception": false,
     "start_time": "2021-12-27T09:59:23.119373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss Optimization\n",
    "Here we have optimized two lossess, the **KL loss** and **reconstruction loss**.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05168,
     "end_time": "2021-12-27T09:59:23.270462",
     "exception": false,
     "start_time": "2021-12-27T09:59:23.218782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## KL Loss\n",
    "\n",
    "The KL divergence tells us how well the probability distribution Q approximates the probability distribution P by calculating the cross-entropy minus the entropy. Intuitively, we can think of that as the statistical measure of how one distribution differs from another.\n",
    "In VAE, let X be the data we want to model, z be latent variable, P(X) be the probability distribution of data, P(z) be the probability distribution of the latent variable and P(X|z) be the distribution of generating data given latent variable.\n",
    "\n",
    "In the case of variational autoencoders, our objective is to infer P(z)\n",
    "from P(z|X). P(z|X) is the probability distribution that projects our data into latent space. But since we do not have the distribution P(z|X), we estimate it using its simpler estimation Q.\n",
    "\n",
    "Now while training our VAE, the encoder should try to learn the simpler distribution Q(z|X)\n",
    "such that it is as close as possible to the actual distribution P(z|X). This is where we use KL divergence as a measure of a difference between two probability distributions. The VAE objective function thus includes this KL divergence term that needs to be minimized.\n",
    "\n",
    "*DKL[Q(z|X)||P(z|X)] = E[ logQ(z|X) − logP(z|X) ]*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050708,
     "end_time": "2021-12-27T09:59:23.371280",
     "exception": false,
     "start_time": "2021-12-27T09:59:23.320572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reconstruction loss\n",
    "As the name suggest, it measures the reconstruction of original input x. This network can be trained by minimizing the reconstruction error, which measures the differences between our original input and the consequent reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:23.484485Z",
     "iopub.status.busy": "2021-12-27T09:59:23.483509Z",
     "iopub.status.idle": "2021-12-27T09:59:23.487282Z",
     "shell.execute_reply": "2021-12-27T09:59:23.486705Z",
     "shell.execute_reply.started": "2021-11-21T01:12:51.316029Z"
    },
    "id": "PWi7z22ZHO_l",
    "papermill": {
     "duration": 0.065935,
     "end_time": "2021-12-27T09:59:23.487401",
     "exception": false,
     "start_time": "2021-12-27T09:59:23.421466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        mean, logvar = model.encode(x)\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        x_logit = model.decode(z)\n",
    "        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "        logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])\n",
    "        logpz = log_normal_pdf(z, 0.0, 0.0)\n",
    "        logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "        loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.binary_crossentropy(x, x_logit)\n",
    "        )\n",
    "        total_loss = reconstruction_loss + loss_KL\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:23.593029Z",
     "iopub.status.busy": "2021-12-27T09:59:23.592052Z",
     "iopub.status.idle": "2021-12-27T09:59:25.214573Z",
     "shell.execute_reply": "2021-12-27T09:59:25.213560Z",
     "shell.execute_reply.started": "2021-11-21T01:12:51.988704Z"
    },
    "id": "zqtNDolCHSao",
    "papermill": {
     "duration": 1.677552,
     "end_time": "2021-12-27T09:59:25.214724",
     "exception": false,
     "start_time": "2021-12-27T09:59:23.537172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim]\n",
    ")\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:25.329073Z",
     "iopub.status.busy": "2021-12-27T09:59:25.327981Z",
     "iopub.status.idle": "2021-12-27T09:59:25.332424Z",
     "shell.execute_reply": "2021-12-27T09:59:25.331787Z",
     "shell.execute_reply.started": "2021-11-21T01:12:52.867858Z"
    },
    "id": "5YymBIlcnMmQ",
    "papermill": {
     "duration": 0.066599,
     "end_time": "2021-12-27T09:59:25.332548",
     "exception": false,
     "start_time": "2021-12-27T09:59:25.265949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_sample, save):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    fig = plt.figure(figsize=(18, 15))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        wave = np.asarray(predictions[i])\n",
    "        librosa.display.waveshow(wave[0], sr=3000)\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
    "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:25.439054Z",
     "iopub.status.busy": "2021-12-27T09:59:25.438306Z",
     "iopub.status.idle": "2021-12-27T09:59:34.199476Z",
     "shell.execute_reply": "2021-12-27T09:59:34.198699Z",
     "shell.execute_reply.started": "2021-11-21T01:12:53.44809Z"
    },
    "id": "qB-85OsqoU2B",
    "papermill": {
     "duration": 8.817499,
     "end_time": "2021-12-27T09:59:34.199685",
     "exception": false,
     "start_time": "2021-12-27T09:59:25.382186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert BATCH_SIZE >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "    test_sample = test_batch[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049615,
     "end_time": "2021-12-27T09:59:34.300333",
     "exception": false,
     "start_time": "2021-12-27T09:59:34.250718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T09:59:34.412268Z",
     "iopub.status.busy": "2021-12-27T09:59:34.411146Z",
     "iopub.status.idle": "2021-12-27T13:33:27.639336Z",
     "shell.execute_reply": "2021-12-27T13:33:27.639884Z",
     "shell.execute_reply.started": "2021-11-21T01:12:59.085341Z"
    },
    "id": "hTt1sUZMYADG",
    "outputId": "df665fc3-de1b-4864-9858-53a671b030a2",
    "papermill": {
     "duration": 12833.290083,
     "end_time": "2021-12-27T13:33:27.640042",
     "exception": false,
     "start_time": "2021-12-27T09:59:34.349959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample, \"jazz\")\n",
    "\n",
    "\n",
    "def train(train_dataset, test_dataset, model, save):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        for train_x in train_dataset:\n",
    "            train_x = np.asarray(train_x)[0]\n",
    "            train_step(model, train_x, optimizer)\n",
    "        end_time = time.time()\n",
    "\n",
    "        loss = tf.keras.metrics.Mean()\n",
    "        for test_x in test_dataset:\n",
    "            test_x = np.asarray(test_x)[0]\n",
    "            loss(compute_loss(model, test_x))\n",
    "        display.clear_output(wait=False)\n",
    "        elbo = -loss.result()\n",
    "        print(\n",
    "            \"Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}\".format(\n",
    "                epoch, elbo, end_time - start_time\n",
    "            )\n",
    "        )\n",
    "        generate_and_save_images(model, epoch, test_sample, save)\n",
    "\n",
    "\n",
    "train(train_dataset, test_dataset, model, \"jazz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:27.751627Z",
     "iopub.status.busy": "2021-12-27T13:33:27.750825Z",
     "iopub.status.idle": "2021-12-27T13:33:32.168482Z",
     "shell.execute_reply": "2021-12-27T13:33:32.167736Z"
    },
    "id": "pQcs-r6cIoRd",
    "papermill": {
     "duration": 4.476903,
     "end_time": "2021-12-27T13:33:32.168613",
     "exception": false,
     "start_time": "2021-12-27T13:33:27.691710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "anim_file_1 = \"jazz_cvae.gif\"\n",
    "\n",
    "with imageio.get_writer(anim_file_1, mode=\"I\") as writer:\n",
    "    filenames = glob.glob(\"jazz*.png\")\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054005,
     "end_time": "2021-12-27T13:33:32.276862",
     "exception": false,
     "start_time": "2021-12-27T13:33:32.222857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:32.444251Z",
     "iopub.status.busy": "2021-12-27T13:33:32.443501Z",
     "iopub.status.idle": "2021-12-27T13:33:32.747552Z",
     "shell.execute_reply": "2021-12-27T13:33:32.748267Z"
    },
    "id": "4lTUTQTmIuRC",
    "outputId": "4e1e5790-033b-4c47-d561-34b4198ec84d",
    "papermill": {
     "duration": 0.415717,
     "end_time": "2021-12-27T13:33:32.748455",
     "exception": false,
     "start_time": "2021-12-27T13:33:32.332738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "\n",
    "embed.embed_file(anim_file_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.100752,
     "end_time": "2021-12-27T13:33:32.948793",
     "exception": false,
     "start_time": "2021-12-27T13:33:32.848041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generated Music - Jazz\n",
    "Let us listen to the music generated by our model, trained only with jazz music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:33.143366Z",
     "iopub.status.busy": "2021-12-27T13:33:33.142093Z",
     "iopub.status.idle": "2021-12-27T13:33:43.087165Z",
     "shell.execute_reply": "2021-12-27T13:33:43.085853Z"
    },
    "papermill": {
     "duration": 10.046453,
     "end_time": "2021-12-27T13:33:43.087299",
     "exception": false,
     "start_time": "2021-12-27T13:33:33.040846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(test_dataset, model):\n",
    "    save_music = []\n",
    "    for test in test_dataset:\n",
    "        mean, logvar = model.encode(test)\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        predictions = model.sample(z)\n",
    "        for pred in predictions:\n",
    "            wave = np.asarray(pred)\n",
    "            save_music.append(wave)\n",
    "    return save_music\n",
    "\n",
    "\n",
    "saved_musics = inference(test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:43.275642Z",
     "iopub.status.busy": "2021-12-27T13:33:43.274489Z",
     "iopub.status.idle": "2021-12-27T13:33:43.289163Z",
     "shell.execute_reply": "2021-12-27T13:33:43.289694Z"
    },
    "id": "7VlU5tcEf-cI",
    "papermill": {
     "duration": 0.113518,
     "end_time": "2021-12-27T13:33:43.289834",
     "exception": false,
     "start_time": "2021-12-27T13:33:43.176316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music1 = saved_musics[0][0]\n",
    "ipd.Audio(music1, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:43.490815Z",
     "iopub.status.busy": "2021-12-27T13:33:43.489727Z",
     "iopub.status.idle": "2021-12-27T13:33:43.503857Z",
     "shell.execute_reply": "2021-12-27T13:33:43.504413Z"
    },
    "id": "Pu4LXmx1jF-2",
    "outputId": "3aa95bb4-eb5a-4ffb-9820-24e5db17bf59",
    "papermill": {
     "duration": 0.117188,
     "end_time": "2021-12-27T13:33:43.504557",
     "exception": false,
     "start_time": "2021-12-27T13:33:43.387369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music2 = saved_musics[9][0]\n",
    "ipd.Audio(music2, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:43.717478Z",
     "iopub.status.busy": "2021-12-27T13:33:43.716378Z",
     "iopub.status.idle": "2021-12-27T13:33:43.732306Z",
     "shell.execute_reply": "2021-12-27T13:33:43.732859Z"
    },
    "papermill": {
     "duration": 0.124758,
     "end_time": "2021-12-27T13:33:43.733009",
     "exception": false,
     "start_time": "2021-12-27T13:33:43.608251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music3 = saved_musics[5][0]\n",
    "ipd.Audio(music3, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:43.952308Z",
     "iopub.status.busy": "2021-12-27T13:33:43.950808Z",
     "iopub.status.idle": "2021-12-27T13:33:43.966012Z",
     "shell.execute_reply": "2021-12-27T13:33:43.966579Z"
    },
    "papermill": {
     "duration": 0.126303,
     "end_time": "2021-12-27T13:33:43.966727",
     "exception": false,
     "start_time": "2021-12-27T13:33:43.840424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music4 = saved_musics[10][0]\n",
    "ipd.Audio(music4, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:44.192002Z",
     "iopub.status.busy": "2021-12-27T13:33:44.190977Z",
     "iopub.status.idle": "2021-12-27T13:33:44.206298Z",
     "shell.execute_reply": "2021-12-27T13:33:44.206827Z"
    },
    "papermill": {
     "duration": 0.130453,
     "end_time": "2021-12-27T13:33:44.206970",
     "exception": false,
     "start_time": "2021-12-27T13:33:44.076517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music5 = saved_musics[8][0]\n",
    "ipd.Audio(music5, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T13:33:44.434774Z",
     "iopub.status.busy": "2021-12-27T13:33:44.433698Z",
     "iopub.status.idle": "2021-12-27T13:33:44.449198Z",
     "shell.execute_reply": "2021-12-27T13:33:44.449767Z"
    },
    "papermill": {
     "duration": 0.129908,
     "end_time": "2021-12-27T13:33:44.449917",
     "exception": false,
     "start_time": "2021-12-27T13:33:44.320009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music6 = saved_musics[7][0]\n",
    "ipd.Audio(music6, rate=3000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.168136,
     "end_time": "2021-12-27T17:08:55.242672",
     "exception": false,
     "start_time": "2021-12-27T17:08:55.074536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generated music - Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:08:55.579446Z",
     "iopub.status.busy": "2021-12-27T17:08:55.578222Z",
     "iopub.status.idle": "2021-12-27T17:09:05.622002Z",
     "shell.execute_reply": "2021-12-27T17:09:05.622574Z"
    },
    "papermill": {
     "duration": 10.217988,
     "end_time": "2021-12-27T17:09:05.622746",
     "exception": false,
     "start_time": "2021-12-27T17:08:55.404758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_music_classic = inference(test_dataset, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:09:05.947851Z",
     "iopub.status.busy": "2021-12-27T17:09:05.946380Z",
     "iopub.status.idle": "2021-12-27T17:09:05.961027Z",
     "shell.execute_reply": "2021-12-27T17:09:05.961581Z"
    },
    "papermill": {
     "duration": 0.182804,
     "end_time": "2021-12-27T17:09:05.961778",
     "exception": false,
     "start_time": "2021-12-27T17:09:05.778974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music1 = save_music_classic[1][0]\n",
    "ipd.Audio(music1, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:09:06.305549Z",
     "iopub.status.busy": "2021-12-27T17:09:06.304430Z",
     "iopub.status.idle": "2021-12-27T17:09:06.318545Z",
     "shell.execute_reply": "2021-12-27T17:09:06.319308Z"
    },
    "papermill": {
     "duration": 0.186448,
     "end_time": "2021-12-27T17:09:06.319493",
     "exception": false,
     "start_time": "2021-12-27T17:09:06.133045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music2 = save_music_classic[9][0]\n",
    "ipd.Audio(music2, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:09:06.677647Z",
     "iopub.status.busy": "2021-12-27T17:09:06.676600Z",
     "iopub.status.idle": "2021-12-27T17:09:06.691741Z",
     "shell.execute_reply": "2021-12-27T17:09:06.692302Z"
    },
    "papermill": {
     "duration": 0.195833,
     "end_time": "2021-12-27T17:09:06.692475",
     "exception": false,
     "start_time": "2021-12-27T17:09:06.496642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music3 = save_music_classic[4][0]\n",
    "ipd.Audio(music3, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:09:07.060616Z",
     "iopub.status.busy": "2021-12-27T17:09:07.059580Z",
     "iopub.status.idle": "2021-12-27T17:09:07.074252Z",
     "shell.execute_reply": "2021-12-27T17:09:07.074797Z"
    },
    "papermill": {
     "duration": 0.197736,
     "end_time": "2021-12-27T17:09:07.074944",
     "exception": false,
     "start_time": "2021-12-27T17:09:06.877208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music4 = save_music_classic[5][0]\n",
    "ipd.Audio(music4, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:09:07.449591Z",
     "iopub.status.busy": "2021-12-27T17:09:07.448477Z",
     "iopub.status.idle": "2021-12-27T17:09:07.463870Z",
     "shell.execute_reply": "2021-12-27T17:09:07.464474Z"
    },
    "papermill": {
     "duration": 0.203766,
     "end_time": "2021-12-27T17:09:07.464630",
     "exception": false,
     "start_time": "2021-12-27T17:09:07.260864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music5 = save_music_classic[8][0]\n",
    "ipd.Audio(music5, rate=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T17:09:07.844946Z",
     "iopub.status.busy": "2021-12-27T17:09:07.842785Z",
     "iopub.status.idle": "2021-12-27T17:09:07.862505Z",
     "shell.execute_reply": "2021-12-27T17:09:07.863168Z"
    },
    "papermill": {
     "duration": 0.208079,
     "end_time": "2021-12-27T17:09:07.863319",
     "exception": false,
     "start_time": "2021-12-27T17:09:07.655240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "music6 = save_music_classic[7][0]\n",
    "ipd.Audio(music6, rate=3000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.184209,
     "end_time": "2021-12-27T17:09:08.238411",
     "exception": false,
     "start_time": "2021-12-27T17:09:08.054202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "We have implemented the model which works only for music generation, for generating a lyrical song this model won't generate a promising result. For generating lyrical songs birectional lstm, transformer networks and attention layers would be a better choice according to me for contructing the network architecture. Also, we have trained my model against a particular category of music, this solution could also be made more interesting by training the model against two or more categories of music."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "Thanks to Victor Basu for creating the Notebook [Generate music with Variational AutoEncoder](https://www.kaggle.com/code/basu369victor/generate-music-with-variational-autoencoder/notebook), lisensed under the [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0). It inspires the majority of the content in this chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "duration": 25844.805755,
   "end_time": "2021-12-27T17:09:09.382067",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-27T09:58:24.576312",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
